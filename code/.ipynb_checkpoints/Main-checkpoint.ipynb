{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining and Machine Learning group project: Team Tissot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team members: **Laux David**, **Randin Samuel**, **Solonin Maksim**, **Vivari√© Romin** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I-Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business problem we chose to study is the prediction of restaurants ratings. Having notice that reviews being often biased, we wanted to adress a data mining and machine learning problem to analyse the impact of the different variables on restaurant ratings. Our aim is to study the potential correlations of features for a restaurant's rating and the comparison of different technics.\n",
    "\n",
    "Our first challenge was to select a Data set with enough features and variables to adress the problem. After evaluating various options we chose a Yelp dataset. \n",
    "Yelp gives access to their dataset (https://www.yelp.com/dataset/challenge) for the USA and Canada. The website offers ten awards of $5'000 to the best solutions proposed by students for the following challenges:  \n",
    "- photo classification  \n",
    "- natural language processing  \n",
    "- Sentiment Analysis and graph mining  \n",
    "\n",
    "This set includes information about local businesses in 10 metropolitan areas across 2 countries. Round 13 of the challenge was launched on January 15, 2019 and will run through December 31, 2019. \n",
    "\n",
    "After downloading the data, we had to convert it to a csv file. \n",
    "The cleaning taks are compile in a file dedicated, <a href=\"http://localhost:8888/notebooks/Documents/GitHub/DMML2019_Team_Tissot/code/DataCleaning.ipynb\">Cleaning Notebook</a>.  \n",
    "The pre-processin tasks are compiled in a notebook dedicated, the <a href=\"http://localhost:8888/notebooks/Documents/GitHub/DMML2019_Team_Tissot/code/Data%20Pre-processing.ipynb\">Pre-processing Notebook</a>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II-Loading the data\n",
    "\n",
    "Same as in EDA notbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn -q\n",
    "!pip install keras -q\n",
    "!pip install tensorflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize\n",
    "import re\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_clean_new.csv\", \n",
    "                          encoding='utf_8', \n",
    "                          dtype = 'unicode',\n",
    "                          parse_dates = True,\n",
    "                          infer_datetime_format = True,\n",
    "                          low_memory=False)\n",
    "df = df.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5    12833\n",
       "4.0    12816\n",
       "3.0     9421\n",
       "4.5     5881\n",
       "2.5     5080\n",
       "2.0     2771\n",
       "1.5      936\n",
       "5.0      931\n",
       "1.0      217\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50839, 78)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns :\n",
    "    if df[column][0] == 'True' or df[column][0] =='False':\n",
    "    #This tests if the column is a boolean by using the first row for efficiency    \n",
    "        df[column] = df[column]=='True'\n",
    "        \n",
    "    #for some columns we have NaN, in that case we test if we find a True or False value\n",
    "    elif \"True\" in df[column].values :\n",
    "        df[column] = df[column]=='True'\n",
    "    elif \"False\" in df[column].values :\n",
    "        df[column] = df[column]=='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_type = [\"American (New)\",\"American (Traditional)\",\"Arts & Entertainment\",\"Asian Fusion\",\"Bakeries\",\"Barbeque\",\"Bars\",\n",
    "\"Beer\",\"Breakfast & Brunch\",\"Buffets\",\"Burgers\",\"Cafes\",\"Canadian (New)\",\"Caribbean\",\"Caterers\",\"Chicken Wings\",\n",
    "\"Chinese\",\"Cocktail Bars\",\"Coffee & Tea\",\"Comfort Food\",\"Delis\",\"Desserts\",\"Diners\",\"Ethnic Food\",\n",
    "\"Event Planning & Services\",\"Fast Food\",\"Food\",\"Food Delivery Services\",\"French\",\"Gastropubs\",\"Gluten-Free\",\n",
    "\"Greek\",\"Grocery\",\"Halal\",\"Hot Dogs\",\"Ice Cream & Frozen Yogurt\",\"Indian\",\"Italian\",\"Japanese\",\"Juice Bars & Smoothies\",\n",
    "\"Korean\",\"Latin American\",\"Lounges\",\"Mediterranean\",\"Mexican\",\"Middle Eastern\",\"Nightlife\",\"Pizza\",\"Pubs\",\n",
    "\"Salad\",\"Sandwiches\",\"Seafood\",\"Soup\",\"Specialty Food\",\"Sports Bars\",\"Steakhouses\",\"Sushi Bars\",\"Tex-Mex\",\n",
    "\"Thai\",\"Vegan\",\"Vegetarian\",\"Vietnamese\",\"Wine & Spirits\",\"Wine Bars\"]\n",
    "\n",
    "ambiance = [\"romantic\",\"intimate\",\"classy\",\"hipster\",\"divey\",\"touristy\",\"trendy\",\"upscale\",\"casual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df[cuisine_type] :\n",
    "    df[column] = df[column]==\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars']=df['stars'].astype(float)\n",
    "df.Price = pd.to_numeric(df.Price, errors='coerce')\n",
    "df = df[np.isfinite(df['Price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'business_id', 'city', 'is_open', 'latitude', 'longitude',\n",
       "       'name', 'postal_code', 'review_count', 'stars', 'state', 'Price',\n",
       "       'American (New)', 'American (Traditional)', 'Arts & Entertainment',\n",
       "       'Asian Fusion', 'Bakeries', 'Barbeque', 'Bars', 'Beer',\n",
       "       'Breakfast & Brunch', 'Buffets', 'Burgers', 'Cafes', 'Canadian (New)',\n",
       "       'Caribbean', 'Caterers', 'Chicken Wings', 'Chinese', 'Cocktail Bars',\n",
       "       'Coffee & Tea', 'Comfort Food', 'Delis', 'Desserts', 'Diners',\n",
       "       'Ethnic Food', 'Event Planning & Services', 'Fast Food', 'Food',\n",
       "       'Food Delivery Services', 'French', 'Gastropubs', 'Gluten-Free',\n",
       "       'Greek', 'Grocery', 'Halal', 'Hot Dogs', 'Ice Cream & Frozen Yogurt',\n",
       "       'Indian', 'Italian', 'Japanese', 'Juice Bars & Smoothies', 'Korean',\n",
       "       'Latin American', 'Lounges', 'Mediterranean', 'Mexican',\n",
       "       'Middle Eastern', 'Nightlife', 'Pizza', 'Pubs', 'Salad', 'Sandwiches',\n",
       "       'Seafood', 'Soup', 'Specialty Food', 'Sports Bars', 'Steakhouses',\n",
       "       'Sushi Bars', 'Tex-Mex', 'Thai', 'Vegan', 'Vegetarian', 'Vietnamese',\n",
       "       'Wine & Spirits', 'Wine Bars', 'Anymusic', 'name_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review_count\"]= df[\"review_count\"].astype(int)\n",
    "df[\"name_length\"]= df[\"name_length\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base rate\n",
    "The base rate is the size of the most common class divided by the size of the dataset.\n",
    "Our accuracy should be better than the default rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common class for the ratings is 3.5\n",
      "The baserate is : 0.25228663034284704\n"
     ]
    }
   ],
   "source": [
    "print(\"The most common class for the ratings is\", df[\"stars\"].mode()[0])\n",
    "\n",
    "baseRate = df[df[\"stars\"] == 3.5].count()[\"stars\"] / df[\"stars\"].count()\n",
    "print(\"The baserate is :\", baseRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 200 restaurants with 1 star rating, thus, we decided to drop it. We also drop string columns, which will not help in prediction (They are mainly related to geography)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df['stars'] != 1]\n",
    "X = X.drop(['stars', \"name\", \"address\", \"business_id\", \"city\", \"state\", 'postal_code', 'latitude', 'longitude'], axis = 1)\n",
    "y = df[\"stars\"][df[\"stars\"] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded_y = lab_enc.fit_transform(y) #we label encode the star ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide our data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/test\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_cl_cnt= int(pd.Series(y_train).value_counts().median()) # median of obs over classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we decided to try two methods to fight severe class imbalance. Just downsampling is not an option (then each class will have 900 observations), thus, we introduce upsampling using SMOTE and upsampling + downsampling to the median number of observations over classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "X_resampled, y_resampled = SMOTE(random_state = 72).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled2, y_resampled2 = SMOTE(random_state = 72, sampling_strategy = {7:med_cl_cnt, 0:med_cl_cnt, 1:med_cl_cnt, 2:med_cl_cnt}).fit_resample(X_train, y_train) # upsampling\n",
    "X_resampled2, y_resampled2 = NearMiss(sampling_strategy = {3:med_cl_cnt, 4:med_cl_cnt, 5:med_cl_cnt, 6:med_cl_cnt}).fit_resample(X_resampled2, y_resampled2) #downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify parameters values for grid search: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersRF = {\n",
    "    'n_estimators': (100,200,300),\n",
    "    'max_depth': (10,20,30)\n",
    "}\n",
    "parametersLR = {\n",
    "    'C': (0.1, 1,100),\n",
    "    'solver': (['saga','lbfgs'])\n",
    "}\n",
    "parametersNN = {\n",
    "    'epochs': ([10, 100]),\n",
    "    'batch_size': ([20,30])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(solver='lbfgs', max_iter=2000, multi_class = \"auto\")\n",
    "LR.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "parameters:\n",
      "{'C': (0.1, 1, 100), 'solver': ['saga', 'lbfgs']}\n",
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:  2.7min remaining:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 192.508s\n",
      "\n",
      "Best score for Logistic Regression: 0.304\n",
      "Best parameters set:\n",
      "\tC: 1\n",
      "\tsolver: 'lbfgs'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(LR, parametersLR, cv=2,\n",
    "                               n_jobs=-1, verbose=1,scoring='accuracy')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    #print(\"pipeline:\", [name for name, _ in pipeline2.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parametersLR)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Logistic Regression: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parametersLR.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model according to gridsearch is the one we tested at the beginning with lbfgs solver and C equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomment, if need to run best model with other params \n",
    "#LR = LogisticRegression(solver='lbfgs',C=1, max_iter=2000, multi_class = \"auto\")\n",
    "#LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34326305025321385"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train accuracy\n",
    "LR.score(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22864197530864197"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"1.5\",\"2\",\"2.5\",\"3\",\"3.5\",\"4\",\"4.5\",\"5\"]\n",
    "\n",
    "#print(classification_report(y_test, LR.predict(X_test), target_names= target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test accuracy is above the baserate but it isn't really a good result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will try both data samples, but still we believe that sticking to one method of upsampling is better (at least more common)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=30, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 200,max_depth = 30)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=30, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators = 200,max_depth = 30)\n",
    "clf2.fit(X_resampled2, y_resampled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "parameters:\n",
      "{'max_depth': (10, 20, 30), 'n_estimators': (100, 200, 300)}\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   40.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 44.420s\n",
      "\n",
      "Best score for Random Forest: 0.314\n",
      "Best parameters set:\n",
      "\tmax_depth: 20\n",
      "\tn_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": # just for multiprocessing purposes\n",
    "    grid_search = GridSearchCV(clf, parametersRF, cv=3,\n",
    "                               n_jobs=-1, verbose=1,scoring='accuracy')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    #print(\"Random Forest:\", [name for name, _ in clf.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parametersRF)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Random Forest: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parametersRF.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=30, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100,max_depth = 30)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.9035596026490066\n",
      "Test accuracy : 0.2884938271604938\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy :\", clf.score(X_resampled, y_resampled))\n",
    "print(\"Test accuracy :\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc upsample + downsample : 0.8656371317652432\n",
      "Test acc upsample + downsample : 0.21985185185185185\n"
     ]
    }
   ],
   "source": [
    "print(\"Train acc upsample + downsample :\", clf2.score(X_resampled2, y_resampled2))\n",
    "print(\"Test acc upsample + downsample :\", clf2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report for upsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.5       0.22      0.31      0.25       197\n",
      "           2       0.21      0.21      0.21       560\n",
      "         2.5       0.21      0.17      0.19      1019\n",
      "           3       0.27      0.22      0.24      1875\n",
      "         3.5       0.31      0.35      0.33      2558\n",
      "           4       0.34      0.38      0.36      2543\n",
      "         4.5       0.28      0.22      0.25      1173\n",
      "           5       0.11      0.12      0.12       200\n",
      "\n",
      "    accuracy                           0.29     10125\n",
      "   macro avg       0.24      0.25      0.24     10125\n",
      "weighted avg       0.28      0.29      0.28     10125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test), target_names= target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report for upsampling + downsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.5       0.21      0.30      0.25       197\n",
      "           2       0.20      0.20      0.20       560\n",
      "         2.5       0.15      0.21      0.18      1019\n",
      "           3       0.26      0.16      0.20      1875\n",
      "         3.5       0.28      0.18      0.22      2558\n",
      "           4       0.27      0.17      0.21      2543\n",
      "         4.5       0.19      0.53      0.28      1173\n",
      "           5       0.08      0.10      0.09       200\n",
      "\n",
      "    accuracy                           0.22     10125\n",
      "   macro avg       0.21      0.23      0.20     10125\n",
      "weighted avg       0.24      0.22      0.21     10125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf2.predict(X_test), target_names= target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01109328 0.37211032 0.03373774 0.01422166 0.00714069 0.00503845\n",
      " 0.00736207 0.00423946 0.00735043 0.00427753 0.00196912 0.01261485\n",
      " 0.0029753  0.00830182 0.00645945 0.00814116 0.00245994 0.00437026\n",
      " 0.00535813 0.00376175 0.00237267 0.00413395 0.00444257 0.00581546\n",
      " 0.00565396 0.00630227 0.00198412 0.00707976 0.01061781 0.00694345\n",
      " 0.00243652 0.0032636  0.0032905  0.00451178 0.00403664 0.00235101\n",
      " 0.00353596 0.00344784 0.00288636 0.00405896 0.00929188 0.0051965\n",
      " 0.00315736 0.00333723 0.00246044 0.00360496 0.00432849 0.00700668\n",
      " 0.00399268 0.00485082 0.00814314 0.00395468 0.00930944 0.01311598\n",
      " 0.00804686 0.00375089 0.00407284 0.00291182 0.00562507 0.00435212\n",
      " 0.0020616  0.00414667 0.00265657 0.00416715 0.00361865 0.00200643\n",
      " 0.00254054 0.00471605 0.25142784]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 442
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X_train,y_train)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are implementing neural network with basic architecture on not sampled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#np.random.seed(1143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_NN():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(69,)))\n",
    "    model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "                              # of the layer above. Here, with a \"rectified linear unit\",\n",
    "                              # we clamp all values below 0 to 0.\n",
    "                           \n",
    "    model.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('softmax')) # This special \"softmax\" activation among other things,\n",
    "                                 # ensures the output is a valid probaility distribution, that is\n",
    "                                 # that its values are all non-negative and sum to 1.\n",
    "    #optimizer = optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "    optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn= model_NN, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stars', \"name\", \"address\", \"business_id\", \"city\", \"state\", 'postal_code', \"longitude\", \"latitude\"], axis = 1)\n",
    "y = df[\"stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_classes = len(y.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=8)\n",
    "y_test = to_categorical(y_test, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32536 samples, validate on 8135 samples\n",
      "Epoch 1/10\n",
      "32536/32536 [==============================] - 1s 34us/step - loss: 1.7491 - accuracy: 0.4278 - val_loss: 1.2088 - val_accuracy: 0.4336\n",
      "Epoch 2/10\n",
      "32536/32536 [==============================] - 1s 26us/step - loss: 1.2081 - accuracy: 0.4338 - val_loss: 1.2157 - val_accuracy: 0.4336\n",
      "Epoch 3/10\n",
      "32536/32536 [==============================] - 1s 26us/step - loss: 1.1868 - accuracy: 0.4348 - val_loss: 1.1879 - val_accuracy: 0.4342\n",
      "Epoch 4/10\n",
      "32536/32536 [==============================] - 1s 26us/step - loss: 1.1800 - accuracy: 0.4358 - val_loss: 1.1826 - val_accuracy: 0.4331\n",
      "Epoch 5/10\n",
      "32536/32536 [==============================] - 1s 26us/step - loss: 1.1742 - accuracy: 0.4370 - val_loss: 1.1810 - val_accuracy: 0.4232\n",
      "Epoch 6/10\n",
      "32536/32536 [==============================] - 1s 26us/step - loss: 1.1688 - accuracy: 0.4367 - val_loss: 1.1687 - val_accuracy: 0.4331\n",
      "Epoch 7/10\n",
      "32536/32536 [==============================] - 1s 25us/step - loss: 1.1679 - accuracy: 0.4373 - val_loss: 1.1700 - val_accuracy: 0.4336\n",
      "Epoch 8/10\n",
      "32536/32536 [==============================] - 1s 26us/step - loss: 1.1680 - accuracy: 0.4374 - val_loss: 1.1711 - val_accuracy: 0.4315\n",
      "Epoch 9/10\n",
      "32536/32536 [==============================] - 1s 25us/step - loss: 1.1713 - accuracy: 0.4369 - val_loss: 1.1759 - val_accuracy: 0.4336\n",
      "Epoch 10/10\n",
      "32536/32536 [==============================] - 1s 26us/step - loss: 1.1644 - accuracy: 0.4401 - val_loss: 1.1640 - val_accuracy: 0.4339\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(X_train, y_train,\n",
    "                       batch_size=64, epochs=10,\n",
    "                       verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4341070055961609"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.score(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, we would like to use mean absolute error as a performance metric for our models, because predicting rating of the restaurant is a classification with ordinal variable. Thus, misclassification of 0.5 star is better than 1.5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "MAE = make_scorer(mean_absolute_error)\n",
    "folds = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model_ordinal = LogisticAT(alpha=0)\n",
    "MAE_RF = cross_val_score(clf,\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    cv=folds,\n",
    "    scoring=MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest MAE : 0.6977486252947599\n"
     ]
    }
   ],
   "source": [
    "print(\"Random forest MAE :\", np.mean(MAE_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (8!=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-edf987cf69da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     scoring=MAE)\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 235\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 score = scorer._score(cached_call, estimator,\n\u001b[0;32m---> 87\u001b[0;31m                                       *args, **kwargs)\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m--> 212\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[1;32m    177\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 178\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[0;32m---> 96\u001b[0;31m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of output (8!=1)"
     ]
    }
   ],
   "source": [
    "MAE_NN = cross_val_score(model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=folds,\n",
    "    scoring=MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAE_NN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-78681d87e871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAE_NN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'MAE_NN' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.mean(MAE_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
