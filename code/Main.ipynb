{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn -q\n",
    "!pip install keras -q\n",
    "!pip install tensorflow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "Same as in EDA notbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize\n",
    "import re\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_clean_new.csv\", \n",
    "                          encoding='utf_8', \n",
    "                          dtype = 'unicode',\n",
    "                          parse_dates = True,\n",
    "                          infer_datetime_format = True,\n",
    "                          low_memory=False)\n",
    "df = df.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5    12833\n",
       "4.0    12816\n",
       "3.0     9421\n",
       "4.5     5881\n",
       "2.5     5080\n",
       "2.0     2771\n",
       "1.5      936\n",
       "5.0      931\n",
       "1.0      217\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns :\n",
    "    if df[column][0] == 'True' or df[column][0] =='False':\n",
    "    #This tests if the column is a boolean by using the first row for efficiency    \n",
    "        df[column] = df[column]=='True'\n",
    "        \n",
    "    #for some columns we have NaN, in that case we test if we find a True or False value\n",
    "    elif \"True\" in df[column].values :\n",
    "        df[column] = df[column]=='True'\n",
    "    elif \"False\" in df[column].values :\n",
    "        df[column] = df[column]=='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_type = [\"American (New)\",\"American (Traditional)\",\"Arts & Entertainment\",\"Asian Fusion\",\"Bakeries\",\"Barbeque\",\"Bars\",\n",
    "\"Beer\",\"Breakfast & Brunch\",\"Buffets\",\"Burgers\",\"Cafes\",\"Canadian (New)\",\"Caribbean\",\"Caterers\",\"Chicken Wings\",\n",
    "\"Chinese\",\"Cocktail Bars\",\"Coffee & Tea\",\"Comfort Food\",\"Delis\",\"Desserts\",\"Diners\",\"Ethnic Food\",\n",
    "\"Event Planning & Services\",\"Fast Food\",\"Food\",\"Food Delivery Services\",\"French\",\"Gastropubs\",\"Gluten-Free\",\n",
    "\"Greek\",\"Grocery\",\"Halal\",\"Hot Dogs\",\"Ice Cream & Frozen Yogurt\",\"Indian\",\"Italian\",\"Japanese\",\"Juice Bars & Smoothies\",\n",
    "\"Korean\",\"Latin American\",\"Lounges\",\"Mediterranean\",\"Mexican\",\"Middle Eastern\",\"Nightlife\",\"Pizza\",\"Pubs\",\n",
    "\"Salad\",\"Sandwiches\",\"Seafood\",\"Soup\",\"Specialty Food\",\"Sports Bars\",\"Steakhouses\",\"Sushi Bars\",\"Tex-Mex\",\n",
    "\"Thai\",\"Vegan\",\"Vegetarian\",\"Vietnamese\",\"Wine & Spirits\",\"Wine Bars\"]\n",
    "\n",
    "ambiance = [\"romantic\",\"intimate\",\"classy\",\"hipster\",\"divey\",\"touristy\",\"trendy\",\"upscale\",\"casual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df[cuisine_type] :\n",
    "    df[column] = df[column]==\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars']=df['stars'].astype(float)\n",
    "df.Price = pd.to_numeric(df.Price, errors='coerce')\n",
    "df = df[np.isfinite(df['Price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'business_id', 'city', 'is_open', 'latitude', 'longitude',\n",
       "       'name', 'postal_code', 'review_count', 'stars', 'state', 'Price',\n",
       "       'American (New)', 'American (Traditional)', 'Arts & Entertainment',\n",
       "       'Asian Fusion', 'Bakeries', 'Barbeque', 'Bars', 'Beer',\n",
       "       'Breakfast & Brunch', 'Buffets', 'Burgers', 'Cafes', 'Canadian (New)',\n",
       "       'Caribbean', 'Caterers', 'Chicken Wings', 'Chinese', 'Cocktail Bars',\n",
       "       'Coffee & Tea', 'Comfort Food', 'Delis', 'Desserts', 'Diners',\n",
       "       'Ethnic Food', 'Event Planning & Services', 'Fast Food', 'Food',\n",
       "       'Food Delivery Services', 'French', 'Gastropubs', 'Gluten-Free',\n",
       "       'Greek', 'Grocery', 'Halal', 'Hot Dogs', 'Ice Cream & Frozen Yogurt',\n",
       "       'Indian', 'Italian', 'Japanese', 'Juice Bars & Smoothies', 'Korean',\n",
       "       'Latin American', 'Lounges', 'Mediterranean', 'Mexican',\n",
       "       'Middle Eastern', 'Nightlife', 'Pizza', 'Pubs', 'Salad', 'Sandwiches',\n",
       "       'Seafood', 'Soup', 'Specialty Food', 'Sports Bars', 'Steakhouses',\n",
       "       'Sushi Bars', 'Tex-Mex', 'Thai', 'Vegan', 'Vegetarian', 'Vietnamese',\n",
       "       'Wine & Spirits', 'Wine Bars', 'Anymusic', 'name_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review_count\"]= df[\"review_count\"].astype(int)\n",
    "df[\"name_length\"]= df[\"name_length\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base rate\n",
    "The base rate is the size of the most common class divided by the size of the dataset.\n",
    "Our accuracy should be better than the default rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common class for the ratings is 3.5\n",
      "The baserate is : 0.25228663034284704\n"
     ]
    }
   ],
   "source": [
    "print(\"The most common class for the ratings is\", df[\"stars\"].mode()[0])\n",
    "\n",
    "baseRate = df[df[\"stars\"] == 3.5].count()[\"stars\"] / df[\"stars\"].count()\n",
    "print(\"The baserate is :\", baseRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean normalisation\n",
    "#df[\"normalized_review_count\"]=(df[\"review_count\"]-df[\"review_count\"].mean())/df[\"review_count\"].std()\n",
    "\n",
    "#min-max normalisation \n",
    "#df[\"normalized_review_count\"]=(df[\"review_count\"]-df[\"review_count\"].min())/(df[\"review_count\"].max()-df[\"review_count\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"filter_stars\"] = df[df[\"stars\"] != 1][\"stars\"]\n",
    "#df[\"filter_stars\"] = df[\"filter_stars\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df['stars'] != 1]\n",
    "X = X.drop(['stars', \"name\", \"address\", \"business_id\", \"city\", \"state\", 'postal_code', 'latitude', 'longitude'], axis = 1)\n",
    "y = df[\"stars\"][df[\"stars\"] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded_y = lab_enc.fit_transform(y) #we label encode the star ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/test\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    10268\n",
       "5    10266\n",
       "3     7539\n",
       "6     4702\n",
       "2     4056\n",
       "1     2202\n",
       "0      736\n",
       "7      729\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_cl_cnt= int(pd.Series(y_train).value_counts().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import AllKNN, NearMiss\n",
    "X_resampled, y_resampled = SMOTE(sampling_strategy = {7:med_cl_cnt, 0:med_cl_cnt, 1:med_cl_cnt, 2:med_cl_cnt}).fit_resample(X_train, y_train) # upsampling\n",
    "X_resampled, y_resampled = NearMiss(sampling_strategy = {3:med_cl_cnt, 4:med_cl_cnt, 5:med_cl_cnt, 6:med_cl_cnt}).fit_resample(X_resampled, y_resampled) #downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4379, 1: 4379, 2: 4379, 3: 4379, 4: 4379, 5: 4379, 6: 4379, 7: 4379}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "unique, counts = numpy.unique(y_resampled, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance classes\n",
    "\n",
    "#balanced = pd.DataFrame(columns=df.columns) #create empty df\n",
    "#for i in df[\"filter_stars\"].dropna().unique():\n",
    "  #  balanced = balanced.append(df[df[\"filter_stars\"] == i].sample(900))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced[\"stars\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = df[[\"name_length\", \"normalized_review_count\", \"Price\", \"American (New)\", \"Sandwiches\"]]\n",
    "#X = balanced.drop([\"stars\",\"filter_stars\", \"name\", \"address\", \"business_id\", \"city\", \"state\", \"review_count\", 'postal_code'], axis = 1)\n",
    "#y = balanced[\"stars\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersRF = {\n",
    "    'n_estimators': (100,200,300),\n",
    "    'max_depth': (10,20,30)\n",
    "}\n",
    "parametersLR = {\n",
    "    'C': (0.1, 1,100),\n",
    "    'solver': (['saga','lbfgs'])\n",
    "}\n",
    "parametersNN = {\n",
    "    'epochs': ([10, 100]),\n",
    "    'batch_size': ([20,30])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(solver='lbfgs', max_iter=2000, multi_class = \"auto\")\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(LR, parametersLR, cv=2,\n",
    "                               n_jobs=-1, verbose=1,scoring='accuracy')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    #print(\"pipeline:\", [name for name, _ in pipeline2.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parametersLR)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Logistic Regression: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parametersLR.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model according to gridsearch is the one we tested at the beginning with lbfgs solver and C equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomment, if need to run best model with other params \n",
    "#LR = LogisticRegression(solver='lbfgs',C=1, max_iter=2000, multi_class = \"auto\")\n",
    "#LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"1.5\",\"2\",\"2.5\",\"3\",\"3.5\",\"4\",\"4.5\",\"5\"]\n",
    "\n",
    "#print(classification_report(y_test, LR.predict(X_test), target_names= target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test accuracy is above the baserate but it isn't really a good result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 200,max_depth = 30)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.8759705412194565\n",
      "Test accuracy : 0.22903703703703704\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy :\", clf.score(X_resampled, y_resampled))\n",
    "print(\"Test accuracy :\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": # just for multiprocessing purposes\n",
    "    grid_search = GridSearchCV(clf, parametersRF, cv=3,\n",
    "                               n_jobs=-1, verbose=1,scoring='accuracy')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    #print(\"Random Forest:\", [name for name, _ in clf.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parametersRF)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Random Forest: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parametersRF.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100,max_depth = 30)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.867121488924412\n",
      "Test accuracy : 0.2308148148148148\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy :\", clf.score(X_resampled, y_resampled))\n",
    "print(\"Test accuracy :\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test), target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X_train,y_train)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "np.random.seed(1143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_NN():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(69,)))\n",
    "    model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "                              # of the layer above. Here, with a \"rectified linear unit\",\n",
    "                              # we clamp all values below 0 to 0.\n",
    "                           \n",
    "    model.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('softmax')) # This special \"softmax\" activation among other things,\n",
    "                                 # ensures the output is a valid probaility distribution, that is\n",
    "                                 # that its values are all non-negative and sum to 1.\n",
    "    #optimizer = optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "    optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn= model_NN, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stars', \"name\", \"address\", \"business_id\", \"city\", \"state\", 'postal_code', \"longitude\", \"latitude\"], axis = 1)\n",
    "y = df[\"stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_classes = len(y.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_resampled, num_classes=8)\n",
    "y_test = to_categorical(y_test, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28025 samples, validate on 7007 samples\n",
      "Epoch 1/10\n",
      "28025/28025 [==============================] - 3s 117us/step - loss: 1.9745 - accuracy: 0.1950 - val_loss: 7.2412 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "28025/28025 [==============================] - 4s 132us/step - loss: 1.8728 - accuracy: 0.2166 - val_loss: 6.3335 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "28025/28025 [==============================] - 2s 78us/step - loss: 1.8855 - accuracy: 0.2106 - val_loss: 5.2682 - val_accuracy: 8.5629e-04\n",
      "Epoch 4/10\n",
      "28025/28025 [==============================] - 4s 137us/step - loss: 1.8607 - accuracy: 0.2186 - val_loss: 6.2097 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "28025/28025 [==============================] - 4s 142us/step - loss: 1.8608 - accuracy: 0.2181 - val_loss: 5.9967 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "28025/28025 [==============================] - 4s 149us/step - loss: 1.8736 - accuracy: 0.2186 - val_loss: 5.8434 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "28025/28025 [==============================] - 3s 109us/step - loss: 1.8715 - accuracy: 0.2127 - val_loss: 5.6151 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "28025/28025 [==============================] - 3s 118us/step - loss: 1.8760 - accuracy: 0.2149 - val_loss: 6.9936 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "28025/28025 [==============================] - 4s 139us/step - loss: 1.8540 - accuracy: 0.2183 - val_loss: 5.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "28025/28025 [==============================] - 4s 144us/step - loss: 1.8886 - accuracy: 0.2072 - val_loss: 5.2978 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(X_resampled, y_train,\n",
    "                       batch_size=64, epochs=10,\n",
    "                       verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1079506203532219"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.score(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
