{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn -q\n",
    "!pip install keras -q\n",
    "!pip install tensorflow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "Same as in EDA notbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize\n",
    "import re\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_clean_new.csv\", \n",
    "                          encoding='utf_8', \n",
    "                          dtype = 'unicode',\n",
    "                          parse_dates = True,\n",
    "                          infer_datetime_format = True,\n",
    "                          low_memory=False)\n",
    "df = df.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5    12833\n",
       "4.0    12816\n",
       "3.0     9421\n",
       "4.5     5881\n",
       "2.5     5080\n",
       "2.0     2771\n",
       "1.5      936\n",
       "5.0      931\n",
       "1.0      217\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns :\n",
    "    if df[column][0] == 'True' or df[column][0] =='False':\n",
    "    #This tests if the column is a boolean by using the first row for efficiency    \n",
    "        df[column] = df[column]=='True'\n",
    "        \n",
    "    #for some columns we have NaN, in that case we test if we find a True or False value\n",
    "    elif \"True\" in df[column].values :\n",
    "        df[column] = df[column]=='True'\n",
    "    elif \"False\" in df[column].values :\n",
    "        df[column] = df[column]=='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_type = [\"American (New)\",\"American (Traditional)\",\"Arts & Entertainment\",\"Asian Fusion\",\"Bakeries\",\"Barbeque\",\"Bars\",\n",
    "\"Beer\",\"Breakfast & Brunch\",\"Buffets\",\"Burgers\",\"Cafes\",\"Canadian (New)\",\"Caribbean\",\"Caterers\",\"Chicken Wings\",\n",
    "\"Chinese\",\"Cocktail Bars\",\"Coffee & Tea\",\"Comfort Food\",\"Delis\",\"Desserts\",\"Diners\",\"Ethnic Food\",\n",
    "\"Event Planning & Services\",\"Fast Food\",\"Food\",\"Food Delivery Services\",\"French\",\"Gastropubs\",\"Gluten-Free\",\n",
    "\"Greek\",\"Grocery\",\"Halal\",\"Hot Dogs\",\"Ice Cream & Frozen Yogurt\",\"Indian\",\"Italian\",\"Japanese\",\"Juice Bars & Smoothies\",\n",
    "\"Korean\",\"Latin American\",\"Lounges\",\"Mediterranean\",\"Mexican\",\"Middle Eastern\",\"Nightlife\",\"Pizza\",\"Pubs\",\n",
    "\"Salad\",\"Sandwiches\",\"Seafood\",\"Soup\",\"Specialty Food\",\"Sports Bars\",\"Steakhouses\",\"Sushi Bars\",\"Tex-Mex\",\n",
    "\"Thai\",\"Vegan\",\"Vegetarian\",\"Vietnamese\",\"Wine & Spirits\",\"Wine Bars\"]\n",
    "\n",
    "ambiance = [\"romantic\",\"intimate\",\"classy\",\"hipster\",\"divey\",\"touristy\",\"trendy\",\"upscale\",\"casual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df[cuisine_type] :\n",
    "    df[column] = df[column]==\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars']=df['stars'].astype(float)\n",
    "df.Price = pd.to_numeric(df.Price, errors='coerce')\n",
    "df = df[np.isfinite(df['Price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'business_id', 'city', 'is_open', 'latitude', 'longitude',\n",
       "       'name', 'postal_code', 'review_count', 'stars', 'state', 'Price',\n",
       "       'American (New)', 'American (Traditional)', 'Arts & Entertainment',\n",
       "       'Asian Fusion', 'Bakeries', 'Barbeque', 'Bars', 'Beer',\n",
       "       'Breakfast & Brunch', 'Buffets', 'Burgers', 'Cafes', 'Canadian (New)',\n",
       "       'Caribbean', 'Caterers', 'Chicken Wings', 'Chinese', 'Cocktail Bars',\n",
       "       'Coffee & Tea', 'Comfort Food', 'Delis', 'Desserts', 'Diners',\n",
       "       'Ethnic Food', 'Event Planning & Services', 'Fast Food', 'Food',\n",
       "       'Food Delivery Services', 'French', 'Gastropubs', 'Gluten-Free',\n",
       "       'Greek', 'Grocery', 'Halal', 'Hot Dogs', 'Ice Cream & Frozen Yogurt',\n",
       "       'Indian', 'Italian', 'Japanese', 'Juice Bars & Smoothies', 'Korean',\n",
       "       'Latin American', 'Lounges', 'Mediterranean', 'Mexican',\n",
       "       'Middle Eastern', 'Nightlife', 'Pizza', 'Pubs', 'Salad', 'Sandwiches',\n",
       "       'Seafood', 'Soup', 'Specialty Food', 'Sports Bars', 'Steakhouses',\n",
       "       'Sushi Bars', 'Tex-Mex', 'Thai', 'Vegan', 'Vegetarian', 'Vietnamese',\n",
       "       'Wine & Spirits', 'Wine Bars', 'Anymusic', 'name_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review_count\"]= df[\"review_count\"].astype(int)\n",
    "df[\"name_length\"]= df[\"name_length\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base rate\n",
    "The base rate is the size of the most common class divided by the size of the dataset.\n",
    "Our accuracy should be better than the default rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common class for the ratings is 3.5\n",
      "The baserate is : 0.25228663034284704\n"
     ]
    }
   ],
   "source": [
    "print(\"The most common class for the ratings is\", df[\"stars\"].mode()[0])\n",
    "\n",
    "baseRate = df[df[\"stars\"] == 3.5].count()[\"stars\"] / df[\"stars\"].count()\n",
    "print(\"The baserate is :\", baseRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 200 restaurants with 1 star rating, thus, we decided to drop it. We also drop string columns, which will not help in prediction (They are mainly related to geography)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df['stars'] != 1]\n",
    "X = X.drop(['stars', \"name\", \"address\", \"business_id\", \"city\", \"state\", 'postal_code', 'latitude', 'longitude'], axis = 1)\n",
    "y = df[\"stars\"][df[\"stars\"] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded_y = lab_enc.fit_transform(y) #we label encode the star ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide our data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/test\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_cl_cnt= int(pd.Series(y_train).value_counts().median()) # median of obs over classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we decided to try two methods to fight severe class imbalance. Just downsampling is not an option (then each class will have 900 observations), thus, we introduce upsampling using SMOTE and upsampling + downsampling to the median number of observations over classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "X_resampled, y_resampled = SMOTE(random_state = 72).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled2, y_resampled2 = SMOTE(random_state = 72, sampling_strategy = {7:med_cl_cnt, 0:med_cl_cnt, 1:med_cl_cnt, 2:med_cl_cnt}).fit_resample(X_train, y_train) # upsampling\n",
    "X_resampled2, y_resampled2 = NearMiss(sampling_strategy = {3:med_cl_cnt, 4:med_cl_cnt, 5:med_cl_cnt, 6:med_cl_cnt}).fit_resample(X_resampled2, y_resampled2) #downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify parameters values for grid search: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersRF = {\n",
    "    'n_estimators': (100,200,300),\n",
    "    'max_depth': (10,20,30)\n",
    "}\n",
    "parametersLR = {\n",
    "    'C': (0.1, 1,100),\n",
    "    'solver': (['saga','lbfgs'])\n",
    "}\n",
    "parametersNN = {\n",
    "    'epochs': ([10, 100]),\n",
    "    'batch_size': ([20,30])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(solver='lbfgs', max_iter=2000, multi_class = \"auto\")\n",
    "LR.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(LR, parametersLR, cv=2,\n",
    "                               n_jobs=-1, verbose=1,scoring='accuracy')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    #print(\"pipeline:\", [name for name, _ in pipeline2.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parametersLR)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Logistic Regression: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parametersLR.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model according to gridsearch is the one we tested at the beginning with lbfgs solver and C equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomment, if need to run best model with other params \n",
    "#LR = LogisticRegression(solver='lbfgs',C=1, max_iter=2000, multi_class = \"auto\")\n",
    "#LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR.score(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"1.5\",\"2\",\"2.5\",\"3\",\"3.5\",\"4\",\"4.5\",\"5\"]\n",
    "\n",
    "#print(classification_report(y_test, LR.predict(X_test), target_names= target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test accuracy is above the baserate but it isn't really a good result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will try both data samples, but still we believe that sticking to one method of upsampling is better (at least more common)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 200,max_depth = 30)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators = 200,max_depth = 30)\n",
    "clf2.fit(X_resampled2, y_resampled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": # just for multiprocessing purposes\n",
    "    grid_search = GridSearchCV(clf, parametersRF, cv=3,\n",
    "                               n_jobs=-1, verbose=1,scoring='accuracy')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    #print(\"Random Forest:\", [name for name, _ in clf.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parametersRF)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Random Forest: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parametersRF.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100,max_depth = 30)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy :\", clf.score(X_resampled, y_resampled))\n",
    "print(\"Test accuracy :\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train acc upsample + downsample :\", clf2.score(X_resampled2, y_resampled2))\n",
    "print(\"Test acc upsample + downsample :\", clf2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report for upsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test), target_names= target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report for upsampling + downsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf2.predict(X_test), target_names= target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X_train,y_train)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are implementing neural network with basic architecture on not sampled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#np.random.seed(1143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_NN():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(69,)))\n",
    "    model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "                              # of the layer above. Here, with a \"rectified linear unit\",\n",
    "                              # we clamp all values below 0 to 0.\n",
    "                           \n",
    "    model.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('softmax')) # This special \"softmax\" activation among other things,\n",
    "                                 # ensures the output is a valid probaility distribution, that is\n",
    "                                 # that its values are all non-negative and sum to 1.\n",
    "    #optimizer = optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "    optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn= model_NN, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stars', \"name\", \"address\", \"business_id\", \"city\", \"state\", 'postal_code', \"longitude\", \"latitude\"], axis = 1)\n",
    "y = df[\"stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_classes = len(y.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=8)\n",
    "y_test = to_categorical(y_test, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hist = model.fit(X_train, y_train,\n",
    "                       batch_size=64, epochs=10,\n",
    "                       verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, we would like to use mean absolute error as a performance metric for our models, because predicting rating of the restaurant is a classification with ordinal variable. Thus, misclassification of 0.5 star is better than 1.5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mord import LogisticAT\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "MAE = make_scorer(mean_absolute_error)\n",
    "folds = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_RF = cross_val_score(clf,\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    cv=folds,\n",
    "    scoring=MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random forest MAE :\", np.mean(MAE_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_NN = cross_val_score(model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=folds,\n",
    "    scoring=MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2363344719636296\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(MAE_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
